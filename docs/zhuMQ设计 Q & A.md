### zhuMQ 是 CP 还是 AP
zhuMQ 通过 ack 机制对于 CP 和 AP 做了一个平衡，ack = -1 保证了 CP，其他情况保证了 AP

### 为什么分区
消息组织方式实际是三种结构：主题-分区-消息。
主题下每条消息只会保存在某一个分区中，而不会保存在多个分区中
- 提供负载均衡的能力，不同分区被放置在不同节点的机器上，每个节点的机器都能独立的执行各自分区的读写请求处理
- 实现系统高伸缩性，可以添加新节点来增加系统吞吐量

#### zhuMQ 是怎么选择分区的
一般会在消息中手动选择需要将该消息发送到哪个 Topic 的哪个 Partition 中，获取到这个信息之后，会先尝试从 Topic_Partition 中获取，这是一个缓存。如果在这里没有找到，就会从 Zookeeper 服务器中获取。

### zhuMQ 的点对点模式和发布订阅模式
主要靠 Consumer Group 机制实现
- 如果所有实例都属于同一个 Group,那就是点对点模式。我们认为同一组内的消费者订阅的 topic 具有类似的处理逻辑，放在同一组提高消费能力
- 如果所有实例分别属于不同的 Group,就是发布订阅模式

### zhuMQ 怎么消费消息
消费消息有两种方式，Pub 和 Pull。

订阅该 Topic 或者 Partition 后需要先调用 StartGet 函数，该函数会发送 RPC 到 zkserver, zkserver 将查询哪些 Broker 负责该 Topic 和 Partition,向这些 Broker 发出通知，做好准备，同时返回需要向集群中请求数据的 Leaders,并保证这些 Brokers 处于在在线状态。当 RPC 返回后，consumer 将连接到这些 Broker 上，向这些 Broker 发出自己的信息，这些 Broker 会连接到 consumer 上，得到一个 RPC 句柄。通过这个句柄使用 Pub 模式消费消息。

### zhuMQ 的副本机制
zkserver 负责崩溃后业务的转移和恢复后的副本复制，就相当于 kafka 中的协调者，他会管理与各 broker 的连接，处理 partition 的状态变化（例如从 Raft 到 Fetch 机制的切换）。

#### 为啥要有副本机制
主要是为了提高系统可靠性和容错能力
- 高可用：在一个节点宕机或不可用时，副本可以接管他的任务，继续为消费者提供服务，确保消息不丢失服务不中断
- 容错：副本机制保证在即使发生硬件故障或其他异常时，数据仍然保留，可以通过副本来恢复数据

#### 副本机制实现模式
采用了 raft 协议和 fetch 机制

#### 副本模式
zhuMQ 中有三种副本模式，通过 ack 来实现.
- ack 机制是用来选择三种模式，三种模式对数据一致性的保证是不一样的，有强一致和弱一致，可通过需要选择，如果需要响应时间短就采用 0 或 1，如果需要可用性强，一致性强就选 -1（三种都支持，kafka有这个机制）
- ack =-1：当消息同步到大多数节点（写入大多数节点磁盘）才返回成功
- ack = 1 ：当消息同步到leader节点（写入leader磁盘）上就返回成功
- ack = 0 ：当消息被leader接收（收到消息就返回）就返回
- 问题：如果不是强一致，需要想办法将0，1 模式未同步到其他副本节点的消息同步过去（我采用的是 fetch 机制，让副本节点做为 consumer 取 pull leader 上的信息，同步到本地磁盘）

#### 如何选举新leader
1、获取当前 Partition 的 Leader 信息
2、检查当前 Leader 是否在线
3、Leader 在线，返回 Leader 的信息
4、不在线 选举新 Leader
- 检查副本是否在线并根据 EndIndex （副本的最新位置）获取最新的副本
- 选举最新的 EndIndex 作为新 Leader


### 消息消费顺序问题
topic 是无序的，但是一个 topic 包含的多个 partition 是有序的。

**「乱序场景1」**

因为一个topic可以有多个partition，kafka只能保证partition内部有序

**「解决方案」**

1、可以设置topic，有且只有一个partition

2、根据业务需要，需要顺序的 指定为同一个partition

3、根据业务需要，比如同一个订单，使用同一个key，可以保证分配到同一个partition上

### zhuMQ 文件高效存储设计
zhuMQ 的消息采用 Go 语言的 gob 包进行消息的编码和解码，支持多种消息格式。

一个 Partition 被划分成多个 Segment ，但是 Segment 并不是终极存储，他由两个部分组成
- 索引文件 index：存储当前数据文件的索引
- 数据文件 log ：以 log 后缀结尾，存储当前索引文件名对应的数据文件
Segment 文件以当前 Partition 的最大偏移量命名


### 顺序读写磁盘提高性能
因为 zhuMQ 的消息是不断追加到文件中的，这个特性可以使得 zhuMQ 充分利用磁盘的顺序读写性能，减少磁盘寻道时间

### 与 kafka 的区别
- kafka 是 consumer 从 broker 中拉取消息，但是 zhuMQ 既支持 consumer 拉取消息，又支持 broker 主动将消息发送给 consumer,通过双向 RPC 实现
- 副本复制机制不同

### 通过一致性哈希算法处理与 Broker 的连接和管理
一致性哈希解决了新增节点或者删除节点是缓存雪崩的问题，本项目中的一致性哈希用于 Partition 应该被存储在哪个 broker 中，并且通过一致性哈希以及已知的 topic_name + part_name 来寻找 其所在的 broker。其负载均衡体现在引入了虚拟节点，一个 broker 对应三个 虚拟的节点 dups,扩充了节点的数量，解决了节点比较少的情况下数据倾斜的问题。 

### 消息如何不漏发
